{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import bz2\n",
    "import cPickle\n",
    "import itertools\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from ddlite import *\n",
    "from ddlite.ddbiolib.datasets import PubMedCentralCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_disease_dictionary():    \n",
    "    dictfile = \"data/dicts/stopwords.txt\"\n",
    "    stopwords = [line.strip().split(\"\\t\")[0] for line in open(dictfile).readlines()]\n",
    "    dictfile = \"data/dicts/umls_diseases_syndromes.bz2\"\n",
    "    diseases = {line.strip().split(\"\\t\")[0]:1 for line in bz2.BZ2File(dictfile, 'rb').readlines()}\n",
    "    diseases = {word:1 for word in diseases if word not in stopwords}\n",
    "    diseases = {word:1 for word in diseases if not word.isupper()}\n",
    "    dictfile = \"data/dicts/ncbi_training_diseases.txt\"\n",
    "    terms = [line.strip().split(\"\\t\")[0] for line in open(dictfile).readlines()]\n",
    "    diseases.update({word:1 for word in terms if word not in stopwords})\n",
    "    diseases = {word:1 for word in terms if not word.isupper()}\n",
    "    return diseases\n",
    "\n",
    "def load_acronym_dictionary():    \n",
    "    dictfile = \"data/dicts/umls_diseases_syndromes.bz2\"\n",
    "    diseases = {line.strip().split(\"\\t\")[0]:1 for line in bz2.BZ2File(dictfile, 'rb').readlines()}\n",
    "    diseases = {word:1 for word in diseases if word.isupper()}\n",
    "    dictfile = \"data/dicts/ncbi_training_diseases.txt\"\n",
    "    terms = [line.strip().split(\"\\t\")[0] for line in open(dictfile).readlines()]\n",
    "    diseases.update({word:1 for word in terms if word.isupper()})\n",
    "    return diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4086\n"
     ]
    }
   ],
   "source": [
    "INDIR = \"data/documents/\"\n",
    "OUTDIR = \"candidates/jason/\"\n",
    "\n",
    "infile = \"{}/pmc-subset/\".format(INDIR)\n",
    "cache = \"{}/pmc-subset-cache/\".format(INDIR)\n",
    "\n",
    "parser = SentenceParser()\n",
    "\n",
    "corpus = PubMedCentralCorpus(infile, parser, cache_path=cache)\n",
    "sentences = [corpus[uid][\"sentences\"] for uid in corpus.documents.keys()]\n",
    "sentences = list(itertools.chain.from_iterable(sentences))\n",
    "    \n",
    "diseases = load_disease_dictionary()\n",
    "acronyms = load_acronym_dictionary()\n",
    "matcher_d = DictionaryMatch(label='D', dictionary=diseases, ignore_case=True)\n",
    "matcher_a = DictionaryMatch(label='D', dictionary=acronyms, ignore_case=False)\n",
    "\n",
    "# dump all candidates to a pickle file\n",
    "M = Union(matcher_a, matcher_d)\n",
    "candidates = Entities(sentences, M)\n",
    "\n",
    "print candidates.num_candidates()\n",
    "candidates.dump_candidates(\"{}/disease-candidates.pkl\".format(OUTDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
