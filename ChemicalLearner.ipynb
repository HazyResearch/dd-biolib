{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training a Chemical Named Entity Tagger\n",
    "\n",
    "This notebook requires pickle file pre-generated candidate entities. Please refer to Part 1 in `ChmeicalExtraction.ipynb` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cPickle\n",
    "import itertools\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from ddlite import *\n",
    "from datasets import *\n",
    "from lexicons import AllUpperNounsMatcher,RuleTokenizedDictionaryMatch\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (18,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Precomputed Candidates\n",
    "Since generating our initial candidate set takes some time, we load a snapshot of all entities identified in our Part 1 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = Entities(\"examples/cache/chem-candidates.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Generation\n",
    "The `CandidateModel` object processes our extracted entity candidates. Since `Entities` object defines a feature generation method, features are automatically created when we initialize a `CandidateModel` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 69084 features for each of 2971 mentions\n"
     ]
    }
   ],
   "source": [
    "model = CandidateModel(candidates)\n",
    "msg = \"Extracted {} features for each of {} mentions\"\n",
    "print msg.format(model.num_feats(), model.num_candidates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ground Truth Data\n",
    "\n",
    "\n",
    "### Annotation with MindTagger\n",
    "Often we lack ground truth (or \"gold\") annotated data for our labeling task. In order to evaluate our labeling functions and learning results, we'll create a small set of ground truth labels for some candidates using Mindtagger. This will highlight each candidate in the sentence in which it appears. We set the response to yes if it is a mention of gene, and no otherwise. If you aren't sure, you can abstain from labeling. In a real application, we would likely want to tag more than 20 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure MindTagger is installed. Hang on!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1200\"\n",
       "            src=\"http://DN0a62f34e.SUNet:8900/#/mindtagger/e4913d7ced192394\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10477d8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.open_mindtagger(num_sample=20, width='100%', height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gold Standard Data\n",
    "For the ChemNDER corpus, we actually have labeled training data, so let's load our gold labels and use those to evaluate our system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('triterpenoids', (1, 2))], [('pentacyclic triterpenoid', (2, 4)), ('taraxer-14-ene', (11, 12)), ('carboxylic acid', (18, 20))], [('2\\xce\\xb1,3\\xce\\xb1-dihydroxytaraxer-14-en-28-oic acid', (6, 11))], [('2\\xce\\xb1,3\\xce\\xb1-diacetyltaraxer-14-en-28-oic acid', (3, 9)), ('2\\xce\\xb1,3\\xce\\xb1-di-O-carbonyl-2\\xce\\xb1,3\\xce\\xb1-dihydroxytaraxer-14-en-28-oic acid', (9, 19)), ('2\\xce\\xb1,3\\xce\\xb1-dipropionyltaraxer-14-en-28-oic acid', (18, 25))], [('3\\xce\\xb2-hydroxytaraxer-14-en-28-oic acid', (6, 10)), ('aleuritolic acid', (9, 16))], [('maprounic acid', (3, 6)), ('aleuritolic acid', (5, 8))], [('maprounic acid', (6, 10)), ('p-bromobenzyl acetylmaprounate', (12, 15))], [('3\\xce\\xb1-hydroxytaraxer-14-en-28-oic acid', (9, 13)), ('isoaleuritolic acid', (12, 19)), ('3\\xce\\xb1-acetyltaraxer-14-en-28-oic acid acetate', (18, 23)), ('aleuritolic acid acetate', (23, 30))], [], [('3-oxo-taraxer-14-ene', (10, 13)), ('taraxerone', (15, 18)), ('\\xce\\xb2-sitosterol', (20, 23)), ('stigmasterol', (24, 29))], []]\n"
     ]
    }
   ],
   "source": [
    "corpus = ChemdnerCorpus('datasets/chemdner_corpus/', parser=SentenceParser(), \n",
    "                        cache_path=\"examples/cache/chemdner/\")\n",
    "\n",
    "dev_set = sorted(corpus.cv[\"development\"].keys())[:250]\n",
    "documents = {doc_id:(corpus[doc_id][\"sentences\"],corpus[doc_id][\"tags\"]) for doc_id in dev_set}\n",
    "sentences, gold_entities = zip(*documents.values())\n",
    "#sentences = list(itertools.chain.from_iterable(sentences))\n",
    "#gold_entities = list(itertools.chain.from_iterable(gold_entities))\n",
    "\n",
    "for x in gold_entities:\n",
    "    print x\n",
    "    break\n",
    "\n",
    "#model.add_mindtagger_tags()\n",
    "#gold = np.zeros((model.num_candidates()))\n",
    "#gold[np.array([48,49,50,51,52,53,54,55,56,58,59,60,61,62,63,64,65,66,68,69,70,\n",
    "#     71,72,73,74,75,76,78,79,80,81,82,83,84,85,86,88,89,90,91])] = np.array([\n",
    "#     -1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,1,-1,1,-1,-1,1,\n",
    "#     -1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1])\n",
    "#model.set_gold_labels(gold)\n",
    "#model.set_holdout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Labeling Functions\n",
    "We want to create a set of functions that weakly predicts a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_window(m, key, n=3):\n",
    "    s = list(m.idxs)\n",
    "    b = len(m.lemmas) - np.max(s)\n",
    "    s.extend([np.max(s) + i for i in range(1, min(b,n+1))])\n",
    "    return key in [m.lemmas[i] for i in s]\n",
    "\n",
    "def pre_window(m, key, n=3):\n",
    "    s = list(m.idxs)\n",
    "    b = np.min(s)\n",
    "    s.extend([b - i for i in range(1, min(b,n+1))])\n",
    "    return key in [m.lemmas[i] for i in s]\n",
    "\n",
    "def LF_mutation(m):\n",
    "    return 1 if 'treat' in [m.lemmas[m.dep_parents[i] - 1] for i in m.idxs] else 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
